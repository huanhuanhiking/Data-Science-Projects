{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'D:/data science/cats and dogs/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image data preprocessing\n",
    "image_size = (112,112)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "class_mode = 'binary' # for multi-class classification problem, use: class_mode = 'category' \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.2 # set validation split\n",
    "    ) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory, # same directory as training data\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_nvidia_geforce_rtx_3080.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              51381248  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 54,167,361\n",
      "Trainable params: 54,167,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\n",
    "\n",
    "VGG_16 = Sequential()\n",
    "VGG_16.add(Conv2D(input_shape=(112,112,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "VGG_16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "VGG_16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "VGG_16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "VGG_16.add(Flatten())\n",
    "\n",
    "VGG_16.add(Dense(1024,activation=\"relu\"))\n",
    "Dropout(0.5)\n",
    "VGG_16.add(Dense(1024,activation=\"relu\"))\n",
    "Dropout(0.5)\n",
    "VGG_16.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "VGG_16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "from keras import optimizers\n",
    "\n",
    "VGG_16.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(\"vgg16_dog_cat.h5\", \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             period=1)\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=10, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "312/312 [==============================] - 139s 445ms/step - loss: 0.6504 - acc: 0.6147 - val_loss: 0.5884 - val_acc: 0.6821\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68209, saving model to vgg16_dog_cat.h5\n",
      "Epoch 2/1000\n",
      "312/312 [==============================] - 118s 379ms/step - loss: 0.5783 - acc: 0.6957 - val_loss: 0.5434 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68209 to 0.71840, saving model to vgg16_dog_cat.h5\n",
      "Epoch 3/1000\n",
      "312/312 [==============================] - 118s 379ms/step - loss: 0.5356 - acc: 0.7287 - val_loss: 0.5243 - val_acc: 0.7308\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71840 to 0.73075, saving model to vgg16_dog_cat.h5\n",
      "Epoch 4/1000\n",
      "312/312 [==============================] - 119s 380ms/step - loss: 0.4889 - acc: 0.7618 - val_loss: 0.4725 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73075 to 0.77532, saving model to vgg16_dog_cat.h5\n",
      "Epoch 5/1000\n",
      "312/312 [==============================] - 118s 378ms/step - loss: 0.4522 - acc: 0.7895 - val_loss: 0.4107 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.77532 to 0.81442, saving model to vgg16_dog_cat.h5\n",
      "Epoch 6/1000\n",
      "312/312 [==============================] - 118s 377ms/step - loss: 0.4198 - acc: 0.8073 - val_loss: 0.4070 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81442\n",
      "Epoch 7/1000\n",
      "312/312 [==============================] - 118s 377ms/step - loss: 0.3877 - acc: 0.8252 - val_loss: 0.3526 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81442 to 0.84684, saving model to vgg16_dog_cat.h5\n",
      "Epoch 8/1000\n",
      "312/312 [==============================] - 118s 377ms/step - loss: 0.3576 - acc: 0.8424 - val_loss: 0.3964 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.84684\n",
      "Epoch 9/1000\n",
      "312/312 [==============================] - 118s 378ms/step - loss: 0.3336 - acc: 0.8527 - val_loss: 0.3689 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.84684\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 10/1000\n",
      "312/312 [==============================] - 117s 376ms/step - loss: 0.2687 - acc: 0.8860 - val_loss: 0.2865 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.84684 to 0.87581, saving model to vgg16_dog_cat.h5\n",
      "Epoch 11/1000\n",
      "312/312 [==============================] - 117s 376ms/step - loss: 0.2521 - acc: 0.8931 - val_loss: 0.2484 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87581 to 0.89911, saving model to vgg16_dog_cat.h5\n",
      "Epoch 12/1000\n",
      "312/312 [==============================] - 117s 375ms/step - loss: 0.2422 - acc: 0.8982 - val_loss: 0.2582 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89911\n",
      "Epoch 13/1000\n",
      "312/312 [==============================] - 117s 375ms/step - loss: 0.2338 - acc: 0.9020 - val_loss: 0.2414 - val_acc: 0.9005\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.89911 to 0.90053, saving model to vgg16_dog_cat.h5\n",
      "Epoch 14/1000\n",
      "312/312 [==============================] - 117s 375ms/step - loss: 0.2218 - acc: 0.9080 - val_loss: 0.2245 - val_acc: 0.9090\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.90053 to 0.90904, saving model to vgg16_dog_cat.h5\n",
      "Epoch 15/1000\n",
      "312/312 [==============================] - 117s 376ms/step - loss: 0.2135 - acc: 0.9117 - val_loss: 0.2456 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90904\n",
      "Epoch 16/1000\n",
      "312/312 [==============================] - 121s 387ms/step - loss: 0.2013 - acc: 0.9193 - val_loss: 0.2158 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.90904 to 0.91025, saving model to vgg16_dog_cat.h5\n",
      "Epoch 17/1000\n",
      "312/312 [==============================] - 120s 384ms/step - loss: 0.1947 - acc: 0.9210 - val_loss: 0.2195 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.91025\n",
      "Epoch 18/1000\n",
      "312/312 [==============================] - 118s 378ms/step - loss: 0.1889 - acc: 0.9207 - val_loss: 0.2049 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.91025 to 0.91633, saving model to vgg16_dog_cat.h5\n",
      "Epoch 19/1000\n",
      "312/312 [==============================] - 120s 383ms/step - loss: 0.1832 - acc: 0.9245 - val_loss: 0.2229 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.91633\n",
      "Epoch 20/1000\n",
      "312/312 [==============================] - 120s 386ms/step - loss: 0.1768 - acc: 0.9289 - val_loss: 0.2016 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.91633 to 0.91754, saving model to vgg16_dog_cat.h5\n",
      "Epoch 21/1000\n",
      "190/312 [=================>............] - ETA: 43s - loss: 0.1734 - acc: 0.9304"
     ]
    }
   ],
   "source": [
    "# fit/train model\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "history = VGG_16.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs,\n",
    "    callbacks=[checkpoint, early, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
